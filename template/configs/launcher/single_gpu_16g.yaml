# @package _group_
name: "single_gpu_16g"
gpus: 1
filename: "${launcher.name}.slurm"
#time: "12:00:00"
hours: 12
#modules: ["pytorch-gpu/py3/1.7.0"]
cmd: "train.py"
partition: null
ntasks: ${launcher.gpus} 
C: "v100-16g"
cpus_per_task: 10
hint: "nomultithread"
gres: "gpu:${launcher.gpus}"
#qos: "qos_gpu-t3"
nodes: 1
ntasks_per_node: 1
